{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import math\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import string\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.load('tfidf.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_json('X_train.json', orient = 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_json('y_train.json', orient = 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19965, 3586)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "veclist = list(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3586"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(veclist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['tfidf'] = veclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = list(y_train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 50, max_features = 'auto', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(veclist, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "rf = load('rf.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeaccents(text):\n",
    "    nfkdform = unicodedata.normalize('NFKD', text)\n",
    "    asctext = nfkdform.encode('ASCII', 'ignore')\n",
    "    return asctext.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(tokens):\n",
    "    return([w for w in tokens if not w in stopwords_ and not w in punctuation_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    termslist = []\n",
    "    corpusvocab = set()\n",
    "    paragraphs = X_train['roomstext']\n",
    "    documents = []\n",
    "    for paragraph in paragraphs:\n",
    "        documents.append(str(paragraph))\n",
    "    texts = []\n",
    "    for document in documents:\n",
    "        soup = BeautifulSoup(document, 'html.parser')\n",
    "        texts.append(soup.get_text())\n",
    "    \n",
    "    ratexts = []\n",
    "    for text in texts:\n",
    "        txt = removeaccents(text)\n",
    "        ratexts.append(txt)\n",
    "\n",
    "    \n",
    "    for text in ratexts:\n",
    "        senttokens = nltk.tokenize.sent_tokenize(text)\n",
    "        tokens = [sent for sent in map(nltk.tokenize.word_tokenize, senttokens)]\n",
    "        lower = [[word.lower() for word in sent] for sent in tokens]\n",
    "        stopwords_ = set(nltk.corpus.stopwords.words('english'))\n",
    "        stopwords_.discard('not')\n",
    "        punctuation_ = set(string.punctuation)\n",
    "        filteredtokens = list(map(filter_tokens, lower))\n",
    "        stemporter = nltk.stem.porter.PorterStemmer()\n",
    "        stemtokens = [list(map(stemporter.stem, word))for word in filteredtokens]\n",
    "        terms = []\n",
    "        vocab = set()\n",
    "        for stems in stemtokens:\n",
    "            for word in stems:\n",
    "                vocab.add(word)\n",
    "                terms.append(word)\n",
    "        termslist.append(terms)\n",
    "        corpusvocab.update(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dococcur = Counter( [word for term in termslist for word in set(term)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq = {k:(v/float(len(termslist))) for k,v in dococcur.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindf = .002\n",
    "vocab = [k for k, v in docfreq.items() if v > mindf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3586"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_json('X_test.json', orient = 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    termslistt = []\n",
    "    corpusvocab = set()\n",
    "    paragraphs = X_test['roomstext']\n",
    "    documents = []\n",
    "    for paragraph in paragraphs:\n",
    "        documents.append(str(paragraph))\n",
    "    texts = []\n",
    "    for document in documents:\n",
    "        soup = BeautifulSoup(document, 'html.parser')\n",
    "        texts.append(soup.get_text())\n",
    "    \n",
    "    ratexts = []\n",
    "    for text in texts:\n",
    "        txt = removeaccents(text)\n",
    "        ratexts.append(txt)\n",
    "\n",
    "    \n",
    "    for text in ratexts:\n",
    "        senttokens = nltk.tokenize.sent_tokenize(text)\n",
    "        tokens = [sent for sent in map(nltk.tokenize.word_tokenize, senttokens)]\n",
    "        lower = [[word.lower() for word in sent] for sent in tokens]\n",
    "        stopwords_ = set(nltk.corpus.stopwords.words('english'))\n",
    "        stopwords_.discard('not')\n",
    "        punctuation_ = set(string.punctuation)\n",
    "        filteredtokens = list(map(filter_tokens, lower))\n",
    "        stemporter = nltk.stem.porter.PorterStemmer()\n",
    "        stemtokens = [list(map(stemporter.stem, word))for word in filteredtokens]\n",
    "        terms = []\n",
    "        tempvocab = set()\n",
    "        for stems in stemtokens:\n",
    "            for word in stems:\n",
    "                tempvocab.add(word)\n",
    "                terms.append(word)\n",
    "        termslistt.append(terms)\n",
    "        corpusvocab.update(tempvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_json('y_test.json', orient = 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3586"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38558"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpusvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorst = np.zeros((len(termslistt), len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6655, 3586)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "termoccur = list(map(lambda term : Counter(term), termslistt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "termfreq = []\n",
    "for i in range(len(termoccur)):\n",
    "    termfreq.append({k : (v / float(len(termslistt[i]))) \n",
    "                    for k, v in termoccur[i].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(termslistt)):\n",
    "    for j in range(len(vocab)):\n",
    "        tempterm = vocab[j]\n",
    "        temptermf = termfreq[i].get(tempterm, 0.0)\n",
    "        termidf = np.log(1+1/docfreq[tempterm])\n",
    "        vectorst[i,j] = temptermf * termidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = np.array(y_test['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "veclistt = list(vectorst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(veclistt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6655"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = 0\n",
    "for i in range(len(ytest)):\n",
    "    summ +=(ytest[i]-pred[i])**2\n",
    "result = summ**.5/len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.85014515096804"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = np.full(6655,np.mean(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = 0\n",
    "for i in range(len(ytest)):\n",
    "    summ +=(ytest[i]-base[i])**2\n",
    "result = summ**.5/len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.670168164490875"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
